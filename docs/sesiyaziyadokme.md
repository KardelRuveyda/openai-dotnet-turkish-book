## Sesi Yazıya Dökme

**Speech-to-Text (STT)** ve **Text-to-Speech (TTS)** teknolojileri üzerine yapılan akademik araştırmalar, yapay zeka ve makine öğrenmesi alanında büyük bir ilgi görmektedir. Bu teknolojiler, insan-makine etkileşimlerinde devrim niteliğinde yenilikler sunarak, hem kişisel hem de profesyonel kullanımda önemli faydalar sağlamaktadır. Araştırmacılar, bu teknolojilerin doğruluğunu artırmak, doğal konuşma deneyimi sunmak ve erişilebilirliği genişletmek için farklı alanlarda çalışmalar yapmaktadırlar. Bu teknolojilerin gelişimi, hem konuşma tanıma hem de konuşma sentezi süreçlerinde yenilikçi yöntemlerin uygulanmasıyla hızlanmaktadır.

## Speech-to-Text (STT) Araştırmaları
**Speech-to-Text (STT)** teknolojileri, insan konuşmasını dijital olarak işleyip metne dönüştüren sistemlerdir. Bu teknolojinin akademik dünyadaki gelişimi, özellikle derin öğrenme modelleri ile hız kazanmıştır. Geleneksel konuşma tanıma yöntemleri genellikle **Hidden Markov Model (HMM)** ve **Gaussian Mixture Model (GMM)** gibi istatistiksel modeller üzerine kurulmuşken, son yıllarda **Convolutional Neural Networks (CNN)** ve **Recurrent Neural Networks (RNN)** gibi derin öğrenme teknikleri konuşma tanıma süreçlerinde devrim yaratmıştır. Özellikle Long Short-Term Memory (LSTM) ağları, konuşma verilerini zaman içerisindeki bağımlılıklarla analiz ederek daha doğru sonuçlar sunmaktadır. Bu araştırmalar, konuşmadaki karmaşık zaman ilişkilerini öğrenme yeteneğini geliştirmekte ve bu sayede daha doğal bir konuşma tanıma süreci sağlamaktadır.

**Whisper** gibi Transformer tabanlı modeller ise son yıllarda akademik ilgiyi üzerine çekmiştir. Transformer mimarisi, büyük veri kümeleri üzerinde eğitilerek farklı dillerde ve aksanlarda daha yüksek doğruluk oranları sunmaktadır. Bu tür modeller, konuşma verilerini daha iyi işleyerek dil modelleme ve kod çözme (decoding) süreçlerinde önemli iyileştirmeler sağlar. Akademik çalışmalarda, bu tür modellerin hem kelime hem de anlam bağlamında daha doğru sonuçlar üretebilmesi için beam search decoding gibi gelişmiş yöntemler kullanılmıştır.

Bir diğer önemli akademik araştırma alanı, çok dilli konuşma tanıma sistemlerinin geliştirilmesidir. Özellikle küresel iletişimde dil bariyerlerini aşmak için bu modellerin farklı dillerde çalışabilir olması büyük bir avantajdır. Araştırmalar, bu tür çok dilli sistemlerin dil bağımsız çalışması veya farklı dil yapılarını öğrenebilmesi için yeni yöntemler geliştirmektedir. Bu da, hem eğitim hem de iş dünyasında dil engellerini azaltan uygulamalar geliştirilmesine olanak tanır.

STT teknolojisinin uygulama alanları da genişlemektedir. Özellikle eğitim ve sağlık sektöründe bu teknoloji önemli bir rol oynamaktadır. Akademik çalışmalar, STT sistemlerinin dil öğreniminde öğrenci performansını artırdığını ve klinik notların sesli girişle tutulması gibi sağlık uygulamalarında verimliliği artırdığını göstermektedir. Toplantı kayıtları, müşteri hizmetleri çağrıları ve video içeriklerinin otomatik transkripsiyonu sayesinde bu verilerin daha kolay analiz edilmesi ve arşivlenmesi sağlanmaktadır.

## Text-to-Speech (TTS) Araştırmaları
**Text-to-Speech (TTS)** teknolojileri ise metin tabanlı bilgiyi sesli hale getirerek, dijital içeriklerin daha erişilebilir olmasını sağlar. TTS teknolojilerinde yapılan akademik araştırmalar, doğal ve insan benzeri ses sentezi üzerinde yoğunlaşmaktadır. Özellikle **WaveNet** gibi derin öğrenme tabanlı yaklaşımlar, insan sesini taklit eden daha kaliteli konuşma sentezi modelleri geliştirilmesini sağlamıştır. **WaveNet**, Google tarafından geliştirilen ve ses sentezinde devrim yaratan bir modeldir. Bu model, ses dalgalarını doğrudan modelleyerek insan sesinin inceliklerini ve tonlamalarını daha iyi yakalamaktadır. Akademik dünyada, WaveNet benzeri modellerin ses sentezinde yüksek kalitede sonuçlar elde ettiği gözlemlenmiştir.

**TTS** teknolojisinde önemli bir diğer araştırma alanı ise prosodi (ses tonu, vurgu ve ritim) ve duygusal ifadelerin modellenmesidir. İnsan konuşmasındaki duygusal tonlamaları taklit etmek, konuşmanın doğallığını artırmada kritik bir rol oynar. Bu alanda yapılan çalışmalar, duygusal ifadeleri daha gerçekçi hale getiren modeller geliştirmek için yeni yöntemler aramaktadır. Duygu modelleme, özellikle sosyal robotik uygulamalarında ve dijital asistanların insanlarla daha doğal bir şekilde etkileşim kurmasında önemli bir rol oynamaktadır.

Gerçek zamanlı uygulamalarda konuşma sentezi hızının artırılması da önemli bir araştırma konusudur. Özellikle sesli asistanlar, chatbotlar ve diğer gerçek zamanlı etkileşim gerektiren sistemlerde düşük gecikmeli ve yüksek kaliteli ses üretimi önemli bir ihtiyaçtır. Araştırmalar, bu sistemlerin daha hızlı ve doğru sonuçlar vermesi için optimize edilmiştir. Akademik çalışmalar, bu süreçte GPU hızlandırma ve paralel işlemleme gibi tekniklerle TTS sentezini daha verimli hale getirmeyi amaçlamaktadır.

TTS teknolojisi ayrıca erişilebilirlik açısından da büyük bir önem taşır. Görme engelli bireyler için metinlerin sesli hale getirilmesi, dijital içeriklere erişim açısından büyük bir avantaj sağlar. Bu, sadece bireysel kullanımda değil, eğitim ve iş dünyasında da büyük faydalar sunar. Akademik araştırmalar, TTS teknolojilerinin bu tür toplumsal faydalarını artırmak için çalışmalar yapmaktadır. Örneğin, sosyal robotlar veya yaşlı bireylerle etkileşim kuran dijital sistemler, TTS ile daha doğal bir konuşma deneyimi sunabilmektedir.

## Speech to Text Örneği
### 1. Gerekli Kütüphaneler ve Çevresel Değişkenler

İlk olarak, OpenAI API'yi kullanmak için gerekli olan **OpenAI.Audio** kütüphanesini dahil ediyoruz. Ayrıca OpenAI API anahtarımızı bir çevresel değişken olarak alıyoruz. Bu anahtar, OpenAI'nin API'larına erişim sağlamak için gereklidir.

```csharp
using OpenAI.Audio;

AudioClient client = new(model: "whisper-1", Environment.GetEnvironmentVariable("OPENAI_API_KEY"));
```

- **AudioClient:** OpenAI API'ye istek yapmak için kullanılan istemci nesnesi.
- **model:** **"whisper-1"**: Burada Whisper modelini kullanıyoruz. Bu model, OpenAI'nin ses tanıma (speech-to-text) modellerinden biridir.
- **Environment.GetEnvironmentVariable("OPENAI_API_KEY"):** API anahtarını çevresel değişkenlerden alır. Bu, güvenlik açısından önemlidir; API anahtarlarını kod içinde sabit olarak yazmak yerine, çevresel değişkenlerle kullanmak önerilir.

### 2. Ses Dosyasını Belirlemek

Ses dosyasının yolunu belirliyoruz. Bu örnekte ses dosyası **Assets** klasöründe yer alan **audio_houseplant_care.mp3** dosyasıdır. **Path.Combine** fonksiyonu kullanılarak platformdan bağımsız olarak dosya yolunu oluşturuyoruz.

```csharp
string audioFilePath = Path.Combine("Assets", "audio_houseplant_care.mp3");
```

### 3. Transkripsiyon Seçenekleri

Ses dosyasının nasıl işleneceğini belirlemek için **AudioTranscriptionOptions** sınıfını kullanıyoruz. Bu sınıf ile transkripsiyonun nasıl yapılacağını belirleyen birkaç seçenek ayarlayabiliyoruz.

```csharp
AudioTranscriptionOptions options = new()
{
    ResponseFormat = AudioTranscriptionFormat.Verbose,
    Granularities = AudioTimestampGranularities.Word | AudioTimestampGranularities.Segment,
};
```

* **ResponseFormat** = **AudioTranscriptionFormat.Verbose**: Bu, transkripsiyonun daha detaylı bir biçimde döndürüleceğini belirtir. Yani sadece metin değil, aynı zamanda kelime ve segment bazında zaman damgaları da döndürülür.
* **Granularities** = **AudioTimestampGranularities.Word | AudioTimestampGranularities.Segment**: Burada iki ayrı ayrıntı seviyesi belirliyoruz:
* **Word**: Her bir kelime için zaman damgası döndürülür.
* **Segment**: Her bir konuşma segmenti için zaman damgası döndürülür. Segmentler, konuşma sırasında duraklamalar olduğunda veya anlamlı bölümler oluşturulduğunda ayrılır.

### 4. Transkripsiyon İşlemi

Ses dosyasını transkribe etmek için **client.TranscribeAudio** metodunu kullanıyoruz. Bu metod, ses dosyasını alır ve belirlenen seçenekler doğrultusunda metne çevirir.

```csharp
AudioTranscription transcription = client.TranscribeAudio(audioFilePath, options);
```
**TranscribeAudio:** Bu metod, ses dosyasını transkribe eder ve sonuçları AudioTranscription nesnesi olarak döner.

### 5. Transkripsiyon Sonucunu Yazdırmak

```csharp
Console.WriteLine("Transcription:");
Console.WriteLine($"{transcription.Text}");
```

Bu aşamada, metin olarak dönen transkripsiyon sonucunu ekrana yazdırıyoruz.

**transcription.Text:** Bu özellik, tüm sesin metin olarak döndürülmüş halidir.

### 6. Kelime Bazlı Zaman Damgalarını Yazdırmak

Daha sonra, transkripsiyondaki her bir kelimenin başlangıç ve bitiş zamanlarını milisaniye cinsinden yazdırıyoruz.

```csharp
Console.WriteLine();
Console.WriteLine($"Words:");
foreach (TranscribedWord word in transcription.Words)
{
    Console.WriteLine($"  {word.Word,15} : {word.Start.TotalMilliseconds,5:0} - {word.End.TotalMilliseconds,5:0}");
}

```

* **transcription.Words:** Bu özellik, her bir kelimenin zaman damgalarını içeren bir koleksiyon döner.
  * **word.Word**: Kelimenin kendisini ifade eder.
  * **word.Start.TotalMilliseconds**: Kelimenin ses dosyasında başladığı zamanı milisaniye cinsinden verir.
  * **word.End.TotalMilliseconds**: Kelimenin ses dosyasında bittiği zamanı milisaniye cinsinden verir.
 
### 7. Segment Bazlı Zaman Damgalarını Yazdırmak

Son olarak, konuşma segmentlerinin başlangıç ve bitiş zamanlarını milisaniye cinsinden yazdırıyoruz.

```csharp
Console.WriteLine();
Console.WriteLine($"Segments:");
foreach (TranscribedSegment segment in transcription.Segments)
{
    Console.WriteLine($"  {segment.Text,90} : {segment.Start.TotalMilliseconds,5:0} - {segment.End.TotalMilliseconds,5:0}");
}
```

* **transcription.Segments**: Bu özellik, ses dosyasında tespit edilen konuşma segmentlerini içerir.
  * **segment.Text**: Segmentin içeriğini, yani konuşulan metni döner.
  * **segment.Start.TotalMilliseconds**: Segmentin ses dosyasında başladığı zaman.
  * **segment.End.TotalMilliseconds**: Segmentin ses dosyasında bittiği zaman.
 
Bu örnekte bir ses dosyasını **Whisper** modeli ile metne dönüştürüp hem kelime hem de segment bazında zaman damgası bilgilerini elde ettik. Bu bilgiler sayesinde sadece sesin ne zaman başladığını ve bittiğini değil, aynı zamanda her bir kelimenin ne zaman söylendiğini ve hangi segmentte olduğunu görebiliyoruz. Whisper modeli, bu tür detaylı transkripsiyonlar için güçlü bir araçtır ve OpenAI'nin API'leri ile kolayca entegre edilebilir.

Eğer birden fazla dosya üzerinde çalışmayı planlıyorsan, her dosya için benzer bir yapı oluşturabilir ve transkripsiyon işlemlerini bu yapı içinde yönetebilirsin.

[Ses dosyasını dinleyin](https://github.com/user-attachments/assets/8467cc3d-0671-4fb7-9097-efd823dd8995)

## Text to Speech Örneği

```csharp
        public static void Example02_SimpleTextToSpeech()
        {
            string apiKey = ConfigReader.ReadApiKeyFromConfig();

            AudioClient client = new("tts-1", apiKey);

            string input = "Bu kitap Developer Summit için"
                + " okuyuculara hazırlanmış ,"
                + " Open AI API "
                + " ile ilgili"
                + " çevrimiçi bir kitaptır.";

            BinaryData speech = client.GenerateSpeech(input, GeneratedSpeechVoice.Alloy);

            using FileStream stream = File.OpenWrite($"{Guid.NewGuid()}.mp3");
            speech.ToStream().CopyTo(stream);
        }
```

Bu kod, OpenAI'nin **Text-to-Speech (TTS)** işlevselliğini kullanarak belirli bir metni sese dönüştüren ve bu sesi bir **.mp3** dosyasına kaydeden bir uygulamadır. İlk olarak, **ConfigReader.ReadApiKeyFromConfig()** fonksiyonu ile API anahtarı yapılandırma dosyasından okunarak, OpenAI hizmetlerine erişim sağlanır. **AudioClient** sınıfı, OpenAI'nin TTS modelini ("tts-1") kullanmak için bir istemci olarak tanımlanır ve bu istemci, kullanıcı tarafından sağlanan metni sese dönüştürmek için kullanılır. Burada kullanılan metin, Türkçe bir içerik olup, OpenAI API ile ilgili çevrimiçi bir kitabın Developer Summit için hazırlandığından bahsetmektedir. **client.GenerateSpeech()** fonksiyonu, metni **GeneratedSpeechVoice.Alloy** sesiyle sese dönüştürür ve sonuç, ham ses verisi olan BinaryData formatında saklanır. Bu ses verisi daha sonra FileStream kullanılarak yerel diske kaydedilir. Dosya adı olarak **Guid.NewGuid()** kullanılarak benzersiz bir kimlik oluşturulur, bu sayede her çalıştırmada farklı bir dosya adı elde edilir. Son olarak, **speech.ToStream().CopyTo(stream)** işlemi ile oluşturulan ses verisi, açılan dosya akışına kopyalanır ve **MP3** formatında kaydedilir. Bu işlem, verilen metni hızlıca sese dönüştürerek bir ses dosyasına dönüştürmek için kullanılır, ve bu dosya yerel diskte saklanır.

[Ses dosyasını dinleyin]([https://github.com/kullanici-adi/proje-adi/raw/main/assets/ornek.mp3](https://github.com/KardelRuveyda/openai-dotnet-turkish-book/blob/main/docs/audio/bef2b700-4995-47f4-a7f3-38146776b5dd.mp3))


## Yapılan Örneğin Önemi

**Speech-to-Text (Sesli İletiden Metne)** ve **Text-to-Speech (Metinden Sese)** teknolojileri, modern dijital dünyada sesli ve yazılı iletişim arasında köprü kuran önemli unsurlardır. Bu teknolojilerin her ikisi de günlük yaşamda, iş dünyasında ve çeşitli sektörlerde geniş bir kullanım alanına sahiptir ve her geçen gün daha fazla entegre edilmektedir. Speech-to-Text teknolojisi, sesli konuşmayı otomatik olarak metne çevirir. Bu teknolojinin önemi, öncelikle erişilebilirlik açısından kendini gösterir. Örneğin, işitme engelli bireyler veya sessiz bir ortamda çalışanlar için konuşmaların otomatik olarak metne dönüştürülmesi büyük bir avantajdır. Canlı altyazı uygulamaları, konferanslar veya derslerde konuşmaları anlık olarak ekrana yansıtabilir, bu da bilgiye erişimi kolaylaştırır. Bunun yanı sıra, konuşarak metin üretmek, verimlilik sağlar. Özellikle iş dünyasında, dikte yoluyla not almak, rapor yazmak veya belgeleri hızlı bir şekilde hazırlamak için bu teknoloji yaygın olarak kullanılır. Sesli veri metne dönüştürüldüğünde, arama yapılabilir, analiz edilebilir ve dijital ortamda arşivlenebilir hale gelir. Özellikle müşteri hizmetleri çağrıları, toplantı kayıtları veya video içerikleri bu yolla metin formatına çevrilerek çok daha kolay işlenebilir ve organize edilebilir. Ayrıca, doğal dil işleme (NLP) sistemleriyle entegre çalışan **Speech-to-Text** teknolojisi, metne dönüştürülen konuşmaların anlamlandırılmasını ve analiz edilmesini sağlar. Örneğin, müşteri hizmetlerine gelen sesli talepler bu teknoloji ile otomatik olarak metne dönüştürülüp analiz edilebilir, böylece hızlı çözümler sunulabilir. Bu teknolojinin bir diğer önemli yönü ise yapay zeka ve büyük veri işleme ile sağladığı olanaklardır. Ses verilerinin metne dönüştürülmesi, bu verilerin yapay zeka ile analiz edilmesini ve örneğin müşteri memnuniyetinin ölçülmesi gibi farklı alanlarda kullanılmasını mümkün kılar. Text-to-Speech (Metinden Sese) ise metin tabanlı içeriklerin sesli hale getirilmesini sağlar. Bu teknoloji, özellikle görme engelli bireyler için veya gözlerini ekrandan ayırmadan bilgiye ulaşmak isteyenler için önemlidir. Bu teknolojiler, günlük hayatı kolaylaştırmanın ötesinde, dijital dünyada bilgiye erişimi demokratikleştirir, iş süreçlerini hızlandırır ve verimliliği artırır.

[Kodu incelemek için buraya tıklayabilirsiniz.](https://github.com/KardelRuveyda/openai-dotnet-exercises/tree/master/Examples/07)
